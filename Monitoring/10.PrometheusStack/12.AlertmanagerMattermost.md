# Alertmanager 설정



# 1. 개요

특정 AP Pod의 CPU 사용률이 일정 임계치를 초과했을 때, Alertmanager가 Mattermost로 알림을 보내는 것을 가이드한다.



## 1) 구성

AP CPU 경고 → Mattermost 알림 구성 가이드

```
[AP Pod Metrics] → [Prometheus] → [Alert Trigger] → [Alertmanager] → [Mattermost Webhook]
```









# 2. Mattermost Webhook

Prometheus Alertmanager 등 외부 시스템에서 Mattermost 채널로 알림을 전송할 수 있도록 **Incoming Webhook URL**을 생성한다.



## 1) Webhook 생성





### (1) Incoming Webhook 활성화 설정

* 메뉴 : 관리자도구 > 통합 > 통합관리
  * Incoming Webhook : 활성화



### (2) 채널 생성

* 메뉴 : Mattermost 채널 선택
  * Add-channels : monitoring-alerts



### (3) Webhook 생성

* 메뉴 : Mattermost(좌측상단) 클릭 > 통합 > 전체 Incoming Webhook > incoming Webhook 추가하기

| **항목**        | **입력 예시**      |
| --------------- | ------------------ |
| **Title**       | Prometheus Alert   |
| **Description** | 알림용 Webhook     |
| **Channel**     | #monitoring-alerts |
| 이채널로 고정   | Check              |



* 생성버튼 클릭

  * 생성 완료 시 다음과 같은 **Webhook URL**이 생성

    * ```
      https://mattermost.example.com/hooks/xxxx-yyy-zzz
      ```

    * 

  * **Webhook URL** 보관할것



### (4) Webhook Test



#### test1

```sh
https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta

$ curl -X POST \
  -H 'Content-Type: application/json' \
  -d '{"text":"🔔 테스트 알림입니다! Mattermost Webhook 연결 성공"}' \
  https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta



🔔 테스트 알림입니다! Mattermost Webhook 연결 성공
```



#### test2

```sh
$ curl -X POST -H 'Content-Type: application/json' \
  -d '{
    "username": "alert-bot",
    "icon_url": "https://www.clipartmax.com/png/full/150-1502115_alarm-icon-red-alert-icon.png",
    "text": ":rotating_light: **TEST ALERT**\n\nCPU usage exceeded 90% on `ap-pod-1`."
  }' \
  https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta
  


:rotating_light: TEST ALERT
CPU usage exceeded 90% on ap-pod-1.





$ curl -X POST -H 'Content-Type: application/json' \
  -d '{"text":"[FIRING] High CPU usage\n• pod-name의 CPU 사용률이 90%입니다."}' \
  https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta

[FIRING] High CPU usage
• pod-name의 CPU 사용률이 90%입니다.

```



| **필드** | **설명**                             |
| -------- | ------------------------------------ |
| username | 메시지를 보낼 봇 이름                |
| icon_url | 봇 아이콘 이미지 URL                 |
| text     | 실제 메시지 텍스트 (markdown 지원됨) |











# 3. Alertmanager 설정



Alertmanager 리소스를 생성할때는 Secret 을 이용한다.

전용 secret 이 있으므로 해당 secret 을 삭제후 다시 생성한다.





## 1) alertmanager.yml 기본

Mattermost로 알림을 보내려면 Alertmanager의 `receivers` 섹션에 Mattermost 설정을 추가해야 한다.

이 리시버를 사용할 `route`를 정의해서 특정 알림이 Mattermost로 전달되도록 구성해야 한다.



### (1) 기본적인 `alertmanager.yml` 구성 예시

```yaml
global:
  # Mattermost로 보낼 때 사용할 기본 설정 (선택 사항)
  # mattermost_api_url: 'your_mattermost_webhook_url'

route:
  group_by: ['alertname']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'mattermost-notifications' # 정의할 리시버 이름

receivers:
- name: 'mattermost-notifications'
  mattermost_configs:
  - api_url: 'your_mattermost_webhook_url' # 실제 Mattermost Webhook URL로 변경
    channel: '#alerts' # 알림을 보낼 Mattermost 채널 (선택 사항, 기본 채널로 보내려면 생략)
    username: 'Alertmanager' # Mattermost에 표시될 알림 발신자 이름 (선택 사항)
    icon_emoji: ':warning:' # Mattermost에 표시될 아이콘 이모지 (선택 사항)
    message: |-
      {{ range .Alerts }}
      **Alert:** {{ .Annotations.summary | default .Labels.alertname }}
      **Severity:** {{ .Labels.severity | default "unknown" }}
      **Description:** {{ .Annotations.description | default .Labels.message }}
      **Start Time:** {{ .StartsAt.Local.Format "2006-01-02 15:04:05" }}
      {{ if .EndsAt.IsZero }}{{ else }}**End Time:** {{ .EndsAt.Local.Format "2006-01-02 15:04:05" }}{{ end }}
      {{ if .GeneratorURL }}**Source:** {{ .GeneratorURL }}{{ end }}
      {{ end }}
```



## 2) alertmanager 설정



```sh
$ cd ~/song/prom-stack

$ cat > alertmanager.yaml

```

```yaml
$ echo '
global:
  resolve_timeout: 5m
  # slack_api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
route:
  receiver: "null"  # 디폴트는 무시 처리
  group_by: ["alertname", "namespace"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        severity: warning
      receiver: "mattermost"
receivers:
  - name: mattermost
    slack_configs:
      - api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
        channel: "#monitoring-alerts"
        send_resolved: true
        title: "{{ .CommonAnnotations.summary }}"
        text: "{{ .CommonAnnotations.description }}"
        #icon_url: 
        #icon_emoji:
  - name: "null"
    webhook_configs: []  # 아무 작업도 하지 않음
' > alertmanager.yaml


```



```sh
# secret 확인
$ kubectl -n monitoring get secret
NAME                                                                                  TYPE                 DATA   AGE
alertmanager-prom-stack-kube-prometheus-alertmanager                                  Opaque               1      17h
alertmanager-prom-stack-kube-prometheus-alertmanager-cluster-tls-config               Opaque               1      17h


# 반드시 삭제후 다시 생성
$ kubectl -n monitoring delete secret alertmanager-prom-stack-kube-prometheus-alertmanager

  kubectl -n monitoring create secret generic alertmanager-prom-stack-kube-prometheus-alertmanager \
  --from-file=alertmanager.yaml
  

```



### (1) sample1

```sh
global:
  resolve_timeout: 5m
route:
  group_by: ["alertname"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        severity: warning     # warning, critical
      receiver: "mattermost-notifications"
    - receiver: "default"     # 다른 알림을 처리할 기본 리시버 (필요한 경우)
receivers:
  - name: "mattermost-notifications"
    mattermost_configs:
      - api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
        channel: "#monitoring-alerts"
  - name: "default"
    # 다른 알림 처리 설정 (예: 로그 파일에 저장)
    pass: {}
  
```

*  `severity="warning"` 레이블을 가진 알림만 Mattermost로 보내도록  `route`를 설정한다.



### (2) sample2

```sh
global:
  resolve_timeout: 5m
route:
  receiver: mattermost
  group_by: ["alertname"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 1h
receivers:
  - name: mattermost
    webhook_configs:
      - url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
        send_resolved: true
        
  
```

*  `severity="warning"` 레이블을 가진 알림만 Mattermost로 보내도록  `route`를 설정한다.



### (3) sample3

```sh
global:
  resolve_timeout: 5m
  slack_api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
route:
  group_by: ["alertname"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        severity: warning     # warning, critical
      receiver: "mattermost"
    - receiver: "default"     # 다른 알림을 처리할 기본 리시버 (필요한 경우)
receivers:
  - name: mattermost
    slack_configs:
      - api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
        channel: "#monitoring-alerts"
        send_resolved: true
        #icon_url: 
        #icon_emoji: 
  - name: "default"
    # 다른 알림 처리 설정 (예: 로그 파일에 저장)
    pass: {}
        
    
    
    


# Whether to notify about resolved alerts.
[ send_resolved: <boolean> | default = false ]

# The Slack webhook URL. Either api_url or api_url_file should be set.
# Defaults to global settings if none are set here.
[ api_url: <secret> | default = global.slack_api_url ]
[ api_url_file: <filepath> | default = global.slack_api_url_file ]

# The channel or user to send notifications to.
channel: <tmpl_string>

# API request data as defined by the Slack webhook API.
[ icon_emoji: <tmpl_string> ]
[ icon_url: <tmpl_string> ]
[ link_names: <boolean> | default = false ]
[ username: <tmpl_string> | default = '{{ template "slack.default.username" . }}' ]
# The following parameters define the attachment.
actions:
  [ <action_config> ... ]
[ callback_id: <tmpl_string> | default = '{{ template "slack.default.callbackid" . }}' ]
[ color: <tmpl_string> | default = '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}' ]
[ fallback: <tmpl_string> | default = '{{ template "slack.default.fallback" . }}' ]
fields:
  [ <field_config> ... ]
[ footer: <tmpl_string> | default = '{{ template "slack.default.footer" . }}' ]
[ mrkdwn_in: '[' <string>, ... ']' | default = ["fallback", "pretext", "text"] ]
[ pretext: <tmpl_string> | default = '{{ template "slack.default.pretext" . }}' ]
[ short_fields: <boolean> | default = false ]
[ text: <tmpl_string> | default = '{{ template "slack.default.text" . }}' ]
[ title: <tmpl_string> | default = '{{ template "slack.default.title" . }}' ]
[ title_link: <tmpl_string> | default = '{{ template "slack.default.titlelink" . }}' ]
[ image_url: <tmpl_string> ]
[ thumb_url: <tmpl_string> ]

# The HTTP client's configuration.
[ http_config: <http_config> | default = global.http_config ]


```

*  `severity="warning"` 레이블을 가진 알림만 Mattermost로 보내도록  `route`를 설정한다.





### (4) sample4

```sh
global:
  resolve_timeout: 5m
  # slack_api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
route:
  group_by: ["alertname"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        namespace: temp
      receiver: "mattermost"
receivers:
  - name: mattermost
    slack_configs:
      - api_url: "https://mm.cbiz.kubepia.net/hooks/795ruu4wzb8spgfkd1hw4j7fta"
        channel: "#monitoring-alerts"
        send_resolved: true
        #icon_url: 
        #icon_emoji:
```

*  `severity="warning"` 레이블을 가진 알림만 Mattermost로 보내도록  `route`를 설정한다.









# 4. Prometheus Alert Rule 정의



## (1) CPU AleretRule 설정

```sh

$ echo '
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ap-cpu-alerts
  labels:
    release: prom-stack   # Helm release name
spec:
  groups:
    - name: ap-cpu.rules
      rules:
        - alert: HighCpuUsage
          expr: sum(rate(container_cpu_usage_seconds_total{namespace="temp", container!="", pod!=""}[1m])) by (pod) > 0.4
          for: 10s
          labels:
            severity: warning
            # namespace: temp
          annotations:
            summary: "CPU 사용이 0.4 core 초과 (Pod: {{ $labels.pod }})"
            description: "{{ $labels.pod }}의 CPU 사용이 0.4core를 초과했습니다."
' | kubectl -n monitoring apply -f -


```

* 조건 설명
  * namespace: "temp" ← 감시할 네임스페이스
  * CPU 사용률: 80% 초과
  * for: 1m  <-- 연속 1분 이상 유지 시 알림 발생
  * container!="" 는 POD 컨테이너 제외 목적
* 주의
  * prom-stack 라벨은 Helm 설치 이름과 반드시 일치해야 Prometheus에 반영된다.

* 다른 사용 가능한 템플릿 변수들

| **변수**                                      | **의미**                          |
| --------------------------------------------- | --------------------------------- |
| {{ .Labels.severity }}                        | Alert Rule 내 정의된 severity     |
| {{ .Annotations.summary }}                    | summary 메시지                    |
| {{ range .Alerts }}{{ .Labels.pod }}{{ end }} | 여러 Alert에서 pod 이름 반복 출력 |







#### 확인

```sh
$ kubectl get prometheusrule -n monitoring
NAME                                                              AGE
ap-cpu-alerts                                                     21s
prom-stack-kube-prometheus-alertmanager.rules                     45m
....


# 삭제시...
$ kubectl -n monitoring delete prometheusrule ap-cpu-alerts


```





## (2) 참고











# 5. 부하 테스트

특정 AP Pod에 CPU 부하를 일시적으로 발생시킨다.

## 1) 대상 AP

```sh

$ echo '
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: userlist
  name: userlist
spec:
  replicas: 1
  selector:
    matchLabels:
      app: userlist
  template:
    metadata:
      labels:
        app: userlist
    spec:
      containers:
      - image: ssongman/userlist:v1
        name: userlist
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "500m"
            memory: "1Gi"
' | kubectl -n temp apply -f -






```



## 2) 부하수행

### (1) 부하1 - curl loop

```sh

$ curl userlist-svc/users/1

# 1초에 한번
$ while true; do curl userlist-svc/users/1; sleep 1; echo ; done

# sleep없이
$ while true; do curl userlist-svc/users/1; echo ; done

```







### (2) 부하2 - ab

#### ab(apache Bench) 실행

```sh
# create deploy
$ kubectl -n temp create deploy ab --image=jordi/ab -- sleep 365d



# 삭제시...
$ kubectl -n temp delete deploy ab



```

#### 부하주기 ★

아래 명령을 2개 터미널에서 실행

```sh
# exec
$ kubectl -n temp exec -it deploy/ab -- sh

$ ab -n 100000 -c 50 http://userlist-svc/users/1

```

| **옵션**  | **설명**                          |
| --------- | --------------------------------- |
| -n 100000 | 총 요청 횟수                      |
| -c 50     | 동시에 보낼 요청 수 (concurrency) |





### (3) CPU사용율 확인

```sh

$ kubectl top pod -n temp


# Prometheus 쿼리
rate(container_cpu_usage_seconds_total{namespace="temp", container!="", pod=~"userlist.*"}[1m])


sum(rate(container_cpu_usage_seconds_total{namespace="temp", container!="", pod!=""}[1m])) by (pod)

```





## 3) Alert 발생 확인

아래와 같이 3가지 방법으로 확인 가능하다.



### (1) alertmanager UI 에서 확인

```sh
https://alertmanager.cbiz.kubepia.net

# “Alerts” 탭에서 HighCpuUsage라는 이름의 알람이 떠 있으면, Prometheus에서 조건이 충족되어 Alertmanager로 전달되었다는 뜻이다.

```



### (2)  Prometheus UI에서 확인

```sh
Alerts 탭 → HighCpuUsage 경고가 “FIRING” 상태인지 확인
	•	“Firing”이면 → Alertmanager로 전달됨



ALERTS{alertname="HighCpuUsage"}  로 조회
ALERTS{alertname="HighCpuUsage", alertstate="firing", pod="userlist-766cdd7986-9wxbp", severity="warning"}


```



### (3) 로그로 확인

```sh
kubectl -n monitoring logs deploy/prom-stack-kube-prometheus-alertmanager

# 알림이 수신되었는지, 수신자(Webhook/Mattermost 등)에 전송되었는지 확인 가능
```







## 4) Mattermost 알림 메시지 예시



기본 메시지는 아래와 유사하게 출력됨

```
CPU 사용률 20% 초과 (Pod: userlist-766cdd7986-9wxbp)
userlist-766cdd7986-9wxbp의 CPU 사용률이 20%를 초과했습니다.




[FIRING] HighCpuUsage
summary: CPU 사용률 80% 초과 (Pod: ap-pod-abc123)
description: ap-pod-abc123의 CPU 사용률이 80%를 초과했습니다.



```



# 6. Alertmanager 상태 전이

Prometheus Alertmanager는 알림 상태와 흐름에 따라 inactive → pending → firing → resolved(복구) 상태로 전이



| **상태** | **설명**                                                     |
| -------- | ------------------------------------------------------------ |
| inactive | 조건이 **만족되지 않음**. 즉, Alert가 발생 조건(expr)을 만족하지 않음. |
| pending  | 조건을 만족했지만 for:로 지정한 **지속 시간**을 아직 채우지 않음. |
| firing   | 조건을 일정 시간 이상 만족해서 **경고가 발송된 상태**.       |
| resolved | 조건이 더 이상 만족되지 않아 **해제된 상태**. Mattermost에서는 초록색 메시지로 표시됨. |







**2. Alertmanager의 route 설정 관련 시간**

route:
  group_by: ["alertname"]
  group_wait: 30s         # 첫 Alert를 모아서 보낼 때 대기 시간 (pending 상태일 수 있음)
  group_interval: 5m      # 동일 그룹에서 새 alert이 생겼을 때 재전송 대기 시간
  repeat_interval: 4h     # firing 상태가 계속 유지될 경우, 동일 alert 재전송 간격,  resolved 상태이면 해지됨(다시시작)



| **항목**        | **설명**                                                     |
| --------------- | ------------------------------------------------------------ |
| group_wait      | 알림 그룹이 시작된 후 첫 알림을 보내기 전까지의 시간         |
| group_interval  | 동일 그룹에 새 알림이 발생한 경우, 다음 알림 전송까지 대기 시간 |
| repeat_interval | 알림이 firing 상태일 때 반복 전송 간격 (리마인더 용도)       |