# NFS_PVC





# 1. 개요

특정 VM에 NFS 를 설치하고 Storage Class 를 구성하는 방안을 살펴본다.



### 아키텍처 구성 개요

* **Master Node**: K3s 클러스터의 제어 및 관리 기능을 담당.
* **Worker Nodes 1, 2, 3**: 애플리케이션 워크로드를 실행.
* **Worker Node 4**: 큰 디스크를 가지고 있으며, **NFS 서버**로 설정하여 모든 노드에서 공유 스토리지로 사용.



**Worker 4번에 **NFS 서버**를 Worker 4번에 설정하고, 이를 Kubernetes 클러스터에서 **StorageClass로 구성하여 모든 노드(Worker 1, 2, 3, 4)에서 공유 스토리지로 사용할 수 있다. 이렇게 하면 모든 파드가 여러 노드에서 동일한 스토리지에 접근할 수 있어 `ReadWriteMany`(RWX) 방식으로 활용할 수 있다.





# 2. 단계별 설정

## 1) **Worker 4번에 NFS 서버 설정**

### (1) **NFS 서버 설치**

Worker 4번에서 NFS 서버를 설정합니다.

```bash

# ubuntu
[ubuntu@nfs-server ~]$ sudo apt-get update
[ubuntu@nfs-server ~]$ sudo apt-get install nfs-kernel-server

# restart 할 서비스들 목록 선택



# 삭제시
sudo apt-get uninstall nfs-kernel-server


```



#### [참고] rocky / centos 에서...

```sh


[rocky@nfs-server ~]$ sudo yum update
[rocky@nfs-server ~]$ sudo yum install nfs-utils


[rocky@nfs-server ~]$ sudo systemctl start nfs-server
[rocky@nfs-server ~]$ sudo systemctl enable nfs-server
[rocky@nfs-server ~]$ systemctl status nfs-server
```





#### 서비스 구동

```sh


$ sudo systemctl start nfs-kernel-server

$ sudo systemctl enable nfs-kernel-server

$ systemctl status nfs-kernel-server

```









### (2) **NFS 공유 디렉터리 생성**

Worker 4번에서 공유할 디렉터리를 생성하고, 해당 디렉터리에 권한을 설정합니다.

```bash
sudo mkdir -p /nfs/share
sudo chown nobody:nogroup /nfs/share
sudo chmod 777 /nfs/share
```



### (3) NFS 공유 설정하기

NFS 공유 설정을 추가(/etc/exports 파일 수정)

```bash
sudo vi /etc/exports
```

파일에 다음 줄을 추가하여 모든 Worker 노드에서 접근 가능하도록 설정합니다.

```bash

# 포멧
[마운트 포인트]    [NFS Client 사설 IP](옵션)


# 실제 입력
/nfs/share   *(rw,sync,no_subtree_check,no_root_squash)


# 샘플
/nfs    192.168.1.52(rw,no_root_squash,sync)

```



#### [참고] exports 파일의 옵션 정보

| **옵션**       | **정보**                                                     |
| -------------- | ------------------------------------------------------------ |
| ro             | 읽기 요청만 허용                                             |
| rw             | 읽기 및 쓰기 요청 허용                                       |
| wdelay         | 다른 쓰기 요청이 진행 중인 경우 디스크에 대한 쓰기 요청을 지연 |
| no_wdelay      | wdelay 기능을 해제                                           |
| root_squash    | 원격으로 연결된 root 사용자가 root 권한을 갖는 것을 방지     |
| no_root_squash | root_squash 기능을 해제                                      |
| all_squash     | root를 포함한 모든 원격 사용자가 root 권한을 갖는 것을 방지  |
| sync           | 변경 사항이 커밋된 후에만 요청에 응답                        |



### (4) **NFS 서버 재시작**

```bash
sudo exportfs -a
sudo systemctl restart nfs-kernel-server
```









## 2) **Worker 1, 2, 3에서 NFS 클라이언트 설정**

### (1) **NFS 클라이언트 설치**

각 Worker 노드(1, 2, 3)에 NFS 클라이언트를 설치합니다.

```bash
sudo apt update
sudo apt install nfs-common

# 서비스 재시작 목록
# Daemons using outdated libraries


# 삭제시...
sudo apt uninstall nfs-common

```



### (2) NFS 서버에 접근 설정

각 Worker 노드에서 NFS Server(Worker 4번)의 NFS 공유 디렉터리에 접근 설정

```bash
# 포멧
sudo mount <worker4-ip>:/nfs/share /mnt

# 실제 설정
sudo mount 172.30.1.34:/nfs/share /mnt

mount 확인
$ df -h
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              1.6G  7.2M  1.6G   1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv   97G   41G   52G  45% /
tmpfs                              7.9G     0  7.9G   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/sda2                          2.0G  253M  1.6G  14% /boot
tmpfs                              1.6G  4.0K  1.6G   1% /run/user/1000
172.30.1.34:/nfs/share              97G   51G   42G  55% /mnt              #  <--- 확인,성공

```





## 3) **K3s 클러스터에서 StorageClass 설정**



### (1) Provisioner 의 두가지 방식

* NFS Client Provisioner
  * 이전에 주로 사용하는 방식이며 현재는 Deprecated 상태임
* **CSI 기반 NFS 드라이버**
  * 현대적이며 Kubernetes 에서 SC 로 자리 잡은 SC 임



### (2) **NFS CSI Driver 설치**

#### provisioner 설치

```sh
$ helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/
  helm repo update

$ helm search repo nfs
NAME                                                    CHART VERSION   APP VERSION     DESCRIPTION
nfs-subdir-external-provisioner/nfs-subdir-exte...      4.0.18          4.0.2           nfs-subdir-external-provisioner is an automatic...
stable/nfs-client-provisioner                           1.2.11          3.1.0           DEPRECATED - nfs-client is an automatic provisi...
stable/nfs-server-provisioner                           1.1.3           2.3.0           DEPRECATED - nfs-server-provisioner is an out-o...


$ 
helm install nfs-csi nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
  --set nfs.server=172.30.1.34 \
  --set nfs.path=/nfs/share


$  kubectl get pod
NAME                                                       READY   STATUS    RESTARTS   AGE
nfs-csi-nfs-subdir-external-provisioner-7999d855d8-bv7rs   1/1     Running   0          72s

```



#### sc 확인

Provisioner 를 설치하면 SC(nfs-client) 가 같이 설정된다.

```sh

$ kubectl get sc
NAME                   PROVISIONER                                             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path (default)   rancher.io/local-path                                   Delete          WaitForFirstConsumer   false                  391d
nfs-client             cluster.local/nfs-csi-nfs-subdir-external-provisioner   Delete          Immediate              true                   15m




$ kubectl get sc nfs-client -o yaml

allowVolumeExpansion: true
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    meta.helm.sh/release-name: nfs-csi
    meta.helm.sh/release-namespace: default
  creationTimestamp: "2024-09-08T01:04:08Z"
  labels:
    app: nfs-subdir-external-provisioner
    app.kubernetes.io/managed-by: Helm
    chart: nfs-subdir-external-provisioner-4.0.18
    heritage: Helm
    release: nfs-csi
  name: nfs-client
  resourceVersion: "143026776"
  uid: a8a1c3d5-6b2d-433d-8689-af1d16a67955
parameters:
  archiveOnDelete: "true"
provisioner: cluster.local/nfs-csi-nfs-subdir-external-provisioner
reclaimPolicy: Delete
volumeBindingMode: Immediate


```





#### [참고] **NFS Client Provisioner 설정**

지금은 사용하지 않는 방식임

```bash
$ helm repo add stable https://charts.helm.sh/stable

$ helm search repo nfs
NAME                            CHART VERSION   APP VERSION     DESCRIPTION
stable/nfs-client-provisioner   1.2.11          3.1.0           DEPRECATED - nfs-client is an automatic provisi...
stable/nfs-server-provisioner   1.1.3           2.3.0           DEPRECATED - nfs-server-provisioner is an out-o...


$ helm install nfs-client-provisioner stable/nfs-client-provisioner \
  --set nfs.server=172.30.1.34 \
  --set nfs.path=/nfs/share


# 삭제시...

$ helm delete nfs-client-provisioner 


$ kubectl get sc
NAME                   PROVISIONER                            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
nfs-client             cluster.local/nfs-client-provisioner   Delete          Immediate              true                   7m56s
# nfs-client 라는 storageClass 가 같이 생긴다.
# 하지만 프로비저닝 되지 않는다.

```

* 위 방식으로 SC 설정후 PVC 생성해보니 아래 오류와 함께 Pending 상태로 유지된다.

  * ```sh
    I0908 00:47:50.057842       1 controller.go:987] provision "yjsong/nfs-pvc" class "nfs-client": started                                                                                                                                                       
    E0908 00:47:50.071015       1 controller.go:1004] provision "yjsong/nfs-pvc" class "nfs-client": unexpected error getting claim reference: selfLink was empty, can't make reference
    ```

  * selfLink 방식은 현재 사용하지 않는다.  요즘은 CSI 기반을 사용함



#### [참고] **StorageClass 정의**

NFS를 기반으로 하는 StorageClass를 정의

```yaml

$ cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage
provisioner: nfs-client
parameters:
  archiveOnDelete: "false"
EOF


NAME                   PROVISIONER                            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path (default)   rancher.io/local-path                  Delete          WaitForFirstConsumer   false                  391d
nfs-client             cluster.local/nfs-client-provisioner   Delete          Immediate              true                   8m24s
nfs-storage            nfs-client                             Delete          Immediate              false                  3s


```





## 4) **PVC 생성 및 파드 사용**

### (1) **PVC YAML**

```yaml

$ cat <<EOF | kubectl -n yjsong apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
  storageClassName: nfs-client
EOF


$ kubectl -n yjsong get pvc
NAME      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nfs-pvc   Bound    pvc-11a3922f-b448-41d1-968f-d7a5b3fb827a   5Gi        RWX            nfs-client     7m47s



# 삭제시...
$ kubectl -n yjsong delete  pvc nfs-pvc
persistentvolumeclaim "nfs-pvc" deleted

```

성공



### (2) NFS 서버 확인

NFS 서버에서 어떻게 생성되나 확인해 보자.

```sh

$ cd /nfs/share

$ ll
drwxrwxrwx 2 root   root    4096 Sep  8 01:08 yjsong-nfs-pvc-pvc-11a3922f-b448-41d1-968f-d7a5b3fb827a/

```

위와 같은 형식으로 pvc directory 가 생성된다.





### (3) **POD에서 NFS PVC 사용**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nfs-test-pod
spec:
  containers:
    - name: test-container
      image: nginx
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: nfs-storage
  volumes:
    - name: nfs-storage
      persistentVolumeClaim:
        claimName: nfs-pvc
```





### (4) PVC 용량 증설

```yaml

$ kubectl -n yjsong edit pvc nfs-pvc
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi                 #  <--- 증설  5Gi --> 6Gi
  storageClassName: nfs-client
EOF


$ kubectl -n yjsong get pvc
NAME      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nfs-pvc   Bound    pvc-11a3922f-b448-41d1-968f-d7a5b3fb827a   5Gi        RWX            nfs-client     17m



# 확장은 안된다.

```

확장 불가





## 5) Clean Up

```sh

# Server 삭제
sudo apt-get uninstall nfs-kernel-server


# Client 삭제
sudo apt uninstall nfs-common

```

