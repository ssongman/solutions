# Network Policy



# 1. 개요

Azure Kubernetes Service (AKS)에서 **Network Policy**를 사용하면 **네트워크 트래픽을 제어**하여 특정 **Pod 간 통신** 및 **Pod과 외부 리소스 간 통신**을 허용하거나 차단할 수 있다. 이를 통해 보안을 강화하고 클러스터 내에서 트래픽 흐름을 세부적으로 관리할 수 있다.



## 1) Network Policy 지원하는 네트워크 플러그인



AKS는 두 가지 네트워크 플러그인에서 Network Policy를 지원한다:

1. **Azure CNI (Container Networking Interface)**:

​	•	Azure 네트워크 리소스를 직접 사용.

​	•	Pod마다 고정 IP를 제공.

​	•	Azure 네이티브 네트워크 기능 통합.

2. **Kubenet**:

​	•	경량 네트워크 플러그인.

​	•	Pod 간 NAT(Network Address Translation) 사용.



**참고**: Network Policy는 클러스터 생성 시 선택한 네트워크 플러그인에 따라 달라지며, Azure CNI를 사용하는 경우 **Calico** Network Policy를 활성화해야 합니다.





## 2) 기본적인 networkpolicy

```yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      app: backend
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
```

* 적용된 *app: backend* 레이블을 통해 네트워크 정책을 pod에 적용
* 수신 규칙은 *app: frontend* 레이블이 있는 Pod의 트래픽만 허용





# 2. AKS 에서 NetworkPolicy

## 1) az aks update

기존 클러스터에 Network Policy를 활성화하려면 아래 명령을 사용한다. 단, 활성화 시 클러스터의 재배포가 필요할 수 있다.

```sh
az aks update \
  --resource-group <ResourceGroupName> \
  --name <ClusterName> \
  --enable-network-policy
  
```



## 2) Network Policy YAML 예제

다음은 특정 Pod에 대해 트래픽을 허용하는 Network Policy YAML 예제

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-specific-pod
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: my-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 80
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: backend
    ports:
    - protocol: TCP
      port: 443

```

**설명**:

* podSelector:
  * 특정 라벨을 가진 Pod에만 정책 적용.
* ingress:
  * frontend 앱에서 my-app으로의 트래픽을 TCP 80번 포트로 허용.
* egress:
  * my-app에서 backend 앱으로의 TCP 443번 포트 트래픽 허용.





# 3. Calico기반 Azure CNI

https://learn.microsoft.com/ko-kr/azure/aks/use-network-policies



## 1) aks update

### calico

```sh
RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks

az aks update \
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --enable-network-policy \
    --network-policy calico
    

# 확인
$ kubectl -n calico-system get pod
NAME                                      READY   STATUS    RESTARTS   AGE
calico-kube-controllers-6568bffdd-zptxg   1/1     Running   0          4m20s
calico-node-5r857                         1/1     Running   0          6m53s
calico-node-kzszx                         1/1     Running   0          4m51s
calico-typha-757c8978bf-nnt5q             1/1     Running   0          4m47s


```



## 2) 예제POD

`server` Pod를 만듭니다. 이 Pod는 TCP 포트 80에서 제공됩니다.

```sh
$ kubectl run server -n demo \
    --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 \
    --labels="app=server" --port=80 \
    --command -- /agnhost serve-hostname --tcp --http=false --port "80"

```



`client` Pod를 만듭니다. 다음 명령은 `client` Pod에서 Bash를 실행합니다.

```sh
$ kubectl run -it client -n demo \
    --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 \
    --command -- bash

```



이제 별도의 창에서 다음 명령을 실행하여 서버 IP를 가져옵니다.

```sh
$ kubectl get pod --output=wide -n demo
NAME     READY   STATUS    RESTARTS   AGE   IP             NODE                                NOMINATED NODE   READINESS GATES
server   1/1     Running   0          11m   10.244.0.107   aks-agentpool-12707882-vmss000001   <none>           <none>


```



## 3) 네트워크 정책 없이 연결 테스트

클라이언트 셸에서 다음 명령을 실행하여 서버와의 연결을 확인합니다. 이전 명령을 실행해 출력에 있는 IP를 사용하여 `server-ip`를 바꿉니다. 연결에 성공하면 출력이 표시되지 않습니다.

```sh
$ /agnhost connect 10.244.0.107:80 --timeout=3s --protocol=tcp

```







## 4) 네트워크 정책으로 연결 테스트

### NetworkPolicy

```sh
$ cat <<EOF | kubectl -n demo apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: demo-policy
  namespace: demo
spec:
  podSelector:
    matchLabels:
      app: server
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: client
    ports:
    - port: 80
      protocol: TCP
EOF



```



이제 클라이언트 셸에서 다음 `/agnhost` 명령을 실행하여 서버와의 연결을 확인합니다.

```console
/agnhost connect <server-ip>:80 --timeout=3s --protocol=tcp
TIMEOUT

```

서버에 `app=server`라는 레이블이 지정되어 있지만 클라이언트에는 레이블이 지정되지 않았기 때문에 트래픽과의 연결이 차단됩니다. 위의 connect 명령은 다음 출력을 생성합니다.

```output
kubectl label pod client -n demo app=client

```



```
/agnhost connect <server-ip>:80 --timeout=3s --protocol=tcp

# 성공

```





## Clean up

클러스터에서 Azure Network Policy Manager 또는 Calico를 제거하려면 다음 명령을 실행합니다.

```sh
# aks network-policy Calico 제거
RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks

$ az aks update
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --network-policy none


# NS Delete
$ kubectl delete namespace demo

```





# 4. Cilium on Azure

관련링크 : https://docs.cilium.io/en/stable/installation/k8s-install-helm/



Azure에서 제공하는 **Cilium 기반 Azure CNI**는 Kubernetes 클러스터에서 네트워킹을 처리하는 Azure CNI(Network Plugin)를 Cilium으로 대체한 것입니다.





AKS에서 Cilium은 두가지 방식으로 설치할 수 있다.

* Bring your own CNI
  * 관리자가 수동으로 설치
  * 관리자가 설치를 완전히 제어할 수 있으므로 더 많은 유연성과 사용자 지정을 제공
  * Azure 네트워크 스택과 기본적으로 통합되지 않음
  * 관리자가 Cilium 업그레이드를 처리해야
* Azure CNI Powered by Cilium
  * AKS가 자동으로 설치
  * Azure 네트워크 스택과 기본적으로 통합
  * 업그레이드는 AKS에서 처리하지만 AKS에서 제어하는 것만큼 유연성과 사용자 지정을 제공하지 않는다.







## 1) Cilium CNI

> Bring your own CNI

* AKS BYOCNI cluster 관련링크
  * https://learn.microsoft.com/en-us/azure/aks/use-byo-cni?tabs=azure-cli



### (1) AKS BYOCNI cluster 생성

```sh


RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks


# Create AKS cluster
# 반드시 network-plugin 을 none 으로 생성
$ az aks create \
    --location koreacentral \
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --network-plugin none \
    --generate-ssh-keys


# credentials
$ az aks get-credentials -n yj-aks -g yj-rg

```



### (2) cilium 설치

```sh


$ helm repo add cilium https://helm.cilium.io/


# 아래 helm install 명령연은 AKS BYOCNI cluster
$ helm install cilium cilium/cilium --version 1.16.4 \
  --namespace kube-system \
  --set aksbyocni.enabled=true \
  --set nodeinit.enabled=true


```





### (3) cilium test



#### cilium cli install

```sh
# mac

CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
CLI_ARCH=amd64
if [ "$(uname -m)" = "arm64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-darwin-${CLI_ARCH}.tar.gz{,.sha256sum}
shasum -a 256 -c cilium-darwin-${CLI_ARCH}.tar.gz.sha256sum
sudo tar xzvfC cilium-darwin-${CLI_ARCH}.tar.gz /usr/local/bin
rm cilium-darwin-${CLI_ARCH}.tar.gz{,.sha256sum}




$ cilium status --wait

    /¯¯\
 /¯¯\__/¯¯\    Cilium:             OK
 \__/¯¯\__/    Operator:           OK
 /¯¯\__/¯¯\    Envoy DaemonSet:    OK
 \__/¯¯\__/    Hubble Relay:       disabled
    \__/       ClusterMesh:        disabled

DaemonSet              cilium             Desired: 3, Ready: 3/3, Available: 3/3
DaemonSet              cilium-envoy       Desired: 3, Ready: 3/3, Available: 3/3
Deployment             cilium-operator    Desired: 2, Ready: 2/2, Available: 2/2
Containers:            cilium             Running: 3
                       cilium-envoy       Running: 3
                       cilium-operator    Running: 2
Cluster Pods:          5/5 managed by Cilium
Helm chart version:    1.16.4
Image versions         cilium             quay.io/cilium/cilium:v1.16.4@sha256:d55ec38938854133e06739b1af237932b9c4dd4e75e9b7b2ca3acc72540a44bf: 3
                       cilium-envoy       quay.io/cilium/cilium-envoy:v1.30.7-1731393961-97edc2815e2c6a174d3d12e71731d54f5d32ea16@sha256:0287b36f70cfbdf54f894160082f4f94d1ee1fb10389f3a95baa6c8e448586ed: 3
                       cilium-operator    quay.io/cilium/operator-generic:v1.16.4@sha256:c55a7cbe19fe0b6b28903a085334edb586a3201add9db56d2122c8485f7a51c5: 2
                       

```



####  cilium test

```sh

$ cilium connectivity test

```











## 2) Cilium 기반 Azure CNI

> Azure CNI Powered by Cilium

Azure CNI powered by Cilium은 기본적으로 L3/L4 계층(IP, 포트)에서만 트래픽을 처리하도록 설계되어 있으며, L7 계층의 정책을 처리할 기능이 없다. 따라서 **ToFQDNs**(도메인 기반 정책)과 같은 Cilium의 고급 기능을 사용할 수 없다.

* 2024.12.18 update
  * 다만, aks preview 를 설치한다면 acns(advanced container network security) 를 사용할 수 있으며
  * 이때는 Cilium 기반 Azure CNI 에서 toFQDN 필터링을 사용할 수 있다.
  * 링크
    * https://learn.microsoft.com/ko-kr/azure/aks/azure-cni-powered-by-cilium
    * https://learn.microsoft.com/ko-kr/azure/aks/advanced-container-networking-services-overview?tabs=cilium



### (1) AKS Cilium install

```sh

RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks

# Cilium 설정
# 네트워크 정책 / 데이터플레인을 Cilium으로 설정
$ az aks update \
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --network-plugin azure \
    --network-plugin-mode overlay \
    --network-dataplane cilium \
    --network-policy cilium

# 한 10분정도 소요된다.
# worker node 가 새로 생기면서 pod 이동이 되는 방식으로 upgrade가 된다.

# 되돌릴 수 없다.
# AKS 클러스터에서 Cilium으로 구동되는 Azure CNI를 사용하도록 설정한 후에는 사용하지 않도록 설정할 수 없다. 
# 다른 네트워크 데이터 평면을 사용하려면 새 AKS 클러스터를 만들어야 한다.


# 확인1
$ kubectl -n kube-system get pod | grep cilium
cilium-2m4tg                                          1/1     Running   0               4m47s
cilium-operator-5d587985c8-bq4kd                      1/1     Running   0               4m58s
cilium-operator-5d587985c8-ztdfk                      1/1     Running   0               4m58s
cilium-vtrrm                                          1/1     Running   0               4m57s


# 확인2
$ kubectl get crd | grep cilium
ciliumcidrgroups.cilium.io                                  2024-12-15T14:31:23Z
ciliumclusterwidenetworkpolicies.cilium.io                  2024-12-15T14:31:26Z
ciliumendpoints.cilium.io                                   2024-12-15T14:31:24Z
ciliumexternalworkloads.cilium.io                           2024-12-15T14:31:23Z
ciliumidentities.cilium.io                                  2024-12-15T14:31:23Z
ciliuml2announcementpolicies.cilium.io                      2024-12-15T14:31:24Z
ciliumloadbalancerippools.cilium.io                         2024-12-15T14:31:23Z
ciliumnetworkpolicies.cilium.io                             2024-12-15T14:31:26Z
ciliumnodeconfigs.cilium.io                                 2024-12-15T14:31:22Z
ciliumnodes.cilium.io                                       2024-12-15T14:31:24Z
ciliumpodippools.cilium.io                                  2024-12-15T14:31:23Z


```

* Kubernetes `NetworkPolicy` 리소스 대신 `CiliumNetworkPolicy` 사용자 지정 리소스를 사용 가능



## 3) hubble ui



```sh

$ cilium hubble enable --ui

```







## 4) 도메인 기반 필터링 설정

Azure 네이티브 네트워크 정책은 IP 또는 네트워크 수준의 제어를 제공하지만, Cilium은 FQDN 기반 제어를 지원하여 도메인 단위의 세부적인 제어가 가능하다.



### (1) CiliumNetworkPolicy

Cilium의 Egress 통신에서 도메인 기반 필터링을 설정하려면 ToFQDNs을 사용합니다.



```sh
cat <<EOF | kubectl -n demo apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-egress-to-specific-domain
spec:
  egress:
    - toFQDNs:
        - matchName: example.com
        - matchName: api.example.com
        - matchName: google.com
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP
  endpointSelector:
    matchLabels:
      app: client
EOF

$ kubectl get CiliumNetworkPolicy -A
NAMESPACE   NAME                              AGE
demo        allow-egress-to-specific-domain   17s


```

**설명:**

* toFQDNs:

​	•	matchName으로 지정된 FQDN(예: example.com)으로의 통신만 허용합니다.

* toPorts:

​	•	TCP 443 포트(HTTPS)에 대한 요청만 허용합니다.

* endpointSelector:

​	•	app: my-app 레이블이 있는 Pod에 정책 적용.



### (2) 예제POD



`client` Pod를 만듭니다. 다음 명령은 `client` Pod에서 Bash를 실행합니다.

```sh
$ kubectl run -it curl -n demo \
    --image=alpine/curl \
    --labels="app=client" \ 
    --command -- sleep 365d

```





```sh
kubectl exec -it <pod-name> -- curl -I https://example.com
kubectl exec -it <pod-name> -- curl -I https://blocked.com

```



허용된 도메인은 정상적으로 응답을 받고, 차단된 도메인은 연결이 실패한다.





### (3) Cilium 및 FQDN 기반 필터링의 제한사항



* **DNS 의존성**:

​	•	ToFQDNs은 DNS 쿼리에 의존하므로, 도메인이 IP로 변환되지 않으면 통신이 차단될 수 있다.

* **DNS 캐싱**:

​	•	도메인의 IP 주소가 변경되면 DNS TTL 이후에 정책이 적용된다.

* **성능**:

​	•	도메인 기반 필터링은 DNS 요청을 모니터링하므로 약간의 성능 오버헤드가 있을 수 있다.


