# Network Policy



# 1. 개요

Azure Kubernetes Service (AKS)에서 **Network Policy**를 사용하면 **네트워크 트래픽을 제어**하여 특정 **Pod 간 통신** 및 **Pod과 외부 리소스 간 통신**을 허용하거나 차단할 수 있다. 이를 통해 보안을 강화하고 클러스터 내에서 트래픽 흐름을 세부적으로 관리할 수 있다.



## 1) Network Policy 지원하는 네트워크 플러그인



AKS는 두 가지 네트워크 플러그인에서 Network Policy를 지원한다:

1. **Azure CNI (Container Networking Interface)**:

​	•	Azure 네트워크 리소스를 직접 사용.

​	•	Pod마다 고정 IP를 제공.

​	•	Azure 네이티브 네트워크 기능 통합.

2. **Kubenet**:

​	•	경량 네트워크 플러그인.

​	•	Pod 간 NAT(Network Address Translation) 사용.



**참고**: Network Policy는 클러스터 생성 시 선택한 네트워크 플러그인에 따라 달라지며, Azure CNI를 사용하는 경우 **Calico** Network Policy를 활성화해야 합니다.





## 2) 기본적인 networkpolicy

```yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      app: backend
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
```

* 적용된 *app: backend* 레이블을 통해 네트워크 정책을 pod에 적용
* 수신 규칙은 *app: frontend* 레이블이 있는 Pod의 트래픽만 허용





# 2. AKS 에서 NetworkPolicy

## 1) az aks update

기존 클러스터에 Network Policy를 활성화하려면 아래 명령을 사용한다. 단, 활성화 시 클러스터의 재배포가 필요할 수 있다.

```sh
az aks update \
  --resource-group <ResourceGroupName> \
  --name <ClusterName> \
  --enable-network-policy
  
```



## 2) Network Policy YAML 예제

다음은 특정 Pod에 대해 트래픽을 허용하는 Network Policy YAML 예제

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-specific-pod
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: my-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 80
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: backend
    ports:
    - protocol: TCP
      port: 443

```

**설명**:

* podSelector:
  * 특정 라벨을 가진 Pod에만 정책 적용.
* ingress:
  * frontend 앱에서 my-app으로의 트래픽을 TCP 80번 포트로 허용.
* egress:
  * my-app에서 backend 앱으로의 TCP 443번 포트 트래픽 허용.





# 3. Calico기반 Azure CNI

https://learn.microsoft.com/ko-kr/azure/aks/use-network-policies



## 1) aks update

### calico

```sh
RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks

az aks update \
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --enable-network-policy \
    --network-policy calico
    

# 확인
$ kubectl -n calico-system get pod
NAME                                      READY   STATUS    RESTARTS   AGE
calico-kube-controllers-6568bffdd-zptxg   1/1     Running   0          4m20s
calico-node-5r857                         1/1     Running   0          6m53s
calico-node-kzszx                         1/1     Running   0          4m51s
calico-typha-757c8978bf-nnt5q             1/1     Running   0          4m47s


```



## 2) 예제POD

`server` Pod를 만듭니다. 이 Pod는 TCP 포트 80에서 제공됩니다.

```sh
$ kubectl run server -n demo \
    --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 \
    --labels="app=server" --port=80 \
    --command -- /agnhost serve-hostname --tcp --http=false --port "80"

```



`client` Pod를 만듭니다. 다음 명령은 `client` Pod에서 Bash를 실행합니다.

```sh
$ kubectl run -it client -n demo \
    --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 \
    --command -- bash

```



이제 별도의 창에서 다음 명령을 실행하여 서버 IP를 가져옵니다.

```sh
$ kubectl get pod --output=wide -n demo
NAME     READY   STATUS    RESTARTS   AGE   IP             NODE                                NOMINATED NODE   READINESS GATES
server   1/1     Running   0          11m   10.244.0.107   aks-agentpool-12707882-vmss000001   <none>           <none>


```



## 3) 네트워크 정책 없이 연결 테스트

클라이언트 셸에서 다음 명령을 실행하여 서버와의 연결을 확인합니다. 이전 명령을 실행해 출력에 있는 IP를 사용하여 `server-ip`를 바꿉니다. 연결에 성공하면 출력이 표시되지 않습니다.

```sh
$ /agnhost connect 10.244.0.107:80 --timeout=3s --protocol=tcp

```







## 4) 네트워크 정책으로 연결 테스트

### NetworkPolicy

```sh
$ cat <<EOF | kubectl -n demo apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: demo-policy
  namespace: demo
spec:
  podSelector:
    matchLabels:
      app: server
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: client
    ports:
    - port: 80
      protocol: TCP
EOF



```



이제 클라이언트 셸에서 다음 `/agnhost` 명령을 실행하여 서버와의 연결을 확인합니다.

```console
/agnhost connect <server-ip>:80 --timeout=3s --protocol=tcp
TIMEOUT

```

서버에 `app=server`라는 레이블이 지정되어 있지만 클라이언트에는 레이블이 지정되지 않았기 때문에 트래픽과의 연결이 차단됩니다. 위의 connect 명령은 다음 출력을 생성합니다.

```output
kubectl label pod client -n demo app=client

```



```
/agnhost connect <server-ip>:80 --timeout=3s --protocol=tcp

# 성공

```





## Clean up

클러스터에서 Azure Network Policy Manager 또는 Calico를 제거하려면 다음 명령을 실행합니다.

```sh
# aks network-policy Calico 제거
RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks

$ az aks update
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --network-policy none


# NS Delete
$ kubectl delete namespace demo

```





# 4. Cilium on Azure

관련링크 : https://docs.cilium.io/en/stable/installation/k8s-install-helm/



Azure에서 제공하는 **Cilium 기반 Azure CNI**는 Kubernetes 클러스터에서 네트워킹을 처리하는 Azure CNI(Network Plugin)를 Cilium으로 대체한 것입니다.





AKS에서 Cilium은 두가지 방식으로 설치할 수 있다.

* Bring your own CNI
  * 관리자가 수동으로 설치
  * 관리자가 설치를 완전히 제어할 수 있으므로 더 많은 유연성과 사용자 지정을 제공
  * Azure 네트워크 스택과 기본적으로 통합되지 않음
  * 관리자가 Cilium 업그레이드를 처리해야
* Azure CNI Powered by Cilium
  * AKS가 자동으로 설치
  * Azure 네트워크 스택과 기본적으로 통합
  * 업그레이드는 AKS에서 처리하지만 AKS에서 제어하는 것만큼 유연성과 사용자 지정을 제공하지 않는다.







## 1) Cilium CNI

> Bring your own CNI

* AKS BYOCNI cluster 관련링크
  * https://learn.microsoft.com/en-us/azure/aks/use-byo-cni?tabs=azure-cli



### (1) AKS BYOCNI cluster 생성

```sh


RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks2


# Create AKS cluster
# 반드시 network-plugin 을 none 으로 생성
$ az aks create \
    --location koreacentral \
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --network-plugin none \
    --generate-ssh-keys


```



### (2) cilium 설치

```sh


$ helm repo add cilium https://helm.cilium.io/


# 아래 helm install 명령연은 AKS BYOCNI cluster
$ helm install cilium cilium/cilium --version 1.16.4 \
  --namespace kube-system \
  --set aksbyocni.enabled=true \
  --set nodeinit.enabled=true


```





### (3) cilium test



#### cilium cli install

```sh
# mac

CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
CLI_ARCH=amd64
if [ "$(uname -m)" = "arm64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-darwin-${CLI_ARCH}.tar.gz{,.sha256sum}
shasum -a 256 -c cilium-darwin-${CLI_ARCH}.tar.gz.sha256sum
sudo tar xzvfC cilium-darwin-${CLI_ARCH}.tar.gz /usr/local/bin
rm cilium-darwin-${CLI_ARCH}.tar.gz{,.sha256sum}




$ cilium status --wait

    /¯¯\
 /¯¯\__/¯¯\    Cilium:             OK
 \__/¯¯\__/    Operator:           OK
 /¯¯\__/¯¯\    Envoy DaemonSet:    OK
 \__/¯¯\__/    Hubble Relay:       disabled
    \__/       ClusterMesh:        disabled

DaemonSet              cilium             Desired: 3, Ready: 3/3, Available: 3/3
DaemonSet              cilium-envoy       Desired: 3, Ready: 3/3, Available: 3/3
Deployment             cilium-operator    Desired: 2, Ready: 2/2, Available: 2/2
Containers:            cilium             Running: 3
                       cilium-envoy       Running: 3
                       cilium-operator    Running: 2
Cluster Pods:          5/5 managed by Cilium
Helm chart version:    1.16.4
Image versions         cilium             quay.io/cilium/cilium:v1.16.4@sha256:d55ec38938854133e06739b1af237932b9c4dd4e75e9b7b2ca3acc72540a44bf: 3
                       cilium-envoy       quay.io/cilium/cilium-envoy:v1.30.7-1731393961-97edc2815e2c6a174d3d12e71731d54f5d32ea16@sha256:0287b36f70cfbdf54f894160082f4f94d1ee1fb10389f3a95baa6c8e448586ed: 3
                       cilium-operator    quay.io/cilium/operator-generic:v1.16.4@sha256:c55a7cbe19fe0b6b28903a085334edb586a3201add9db56d2122c8485f7a51c5: 2
                       

```



####  cilium test

```sh

$ cilium connectivity test

```











## 2) Cilium 기반 Azure CNI

> Azure CNI Powered by Cilium

Azure CNI powered by Cilium은 기본적으로 L3/L4 계층(IP, 포트)에서만 트래픽을 처리하도록 설계되어 있으며, L7 계층의 정책을 처리할 기능이 없다. 따라서 **ToFQDNs**(도메인 기반 정책)과 같은 Cilium의 고급 기능을 사용할 수 없다.

* 2024.12.18 update
  * 다만, aks preview 를 설치한다면 acns(advanced container network security) 를 사용할 수 있으며
  * 이때는 Cilium 기반 Azure CNI 에서 toFQDN 필터링을 사용할 수 있다.



### (1) AKS Cilium install

```sh

RESOURCE_GROUP_NAME=yj-rg
CLUSTER_NAME=yj-aks

# Cilium 설정
# 네트워크 정책 / 데이터플레인을 Cilium으로 설정
$ az aks update \
    --resource-group $RESOURCE_GROUP_NAME \
    --name $CLUSTER_NAME \
    --network-plugin azure \
    --network-plugin-mode overlay \
    --network-dataplane cilium \
    --network-policy cilium

# 한 10분정도 소요된다.
# worker node 가 새로 생기면서 pod 이동이 되는 방식으로 upgrade가 된다.

# 되돌릴 수 없다.
# AKS 클러스터에서 Cilium으로 구동되는 Azure CNI를 사용하도록 설정한 후에는 사용하지 않도록 설정할 수 없다. 
# 다른 네트워크 데이터 평면을 사용하려면 새 AKS 클러스터를 만들어야 한다.


# 확인1
$ kubectl -n kube-system get pod | grep cilium
cilium-2m4tg                                          1/1     Running   0               4m47s
cilium-operator-5d587985c8-bq4kd                      1/1     Running   0               4m58s
cilium-operator-5d587985c8-ztdfk                      1/1     Running   0               4m58s
cilium-vtrrm                                          1/1     Running   0               4m57s


# 확인2
$ kubectl get crd | grep cilium
ciliumcidrgroups.cilium.io                                  2024-12-15T14:31:23Z
ciliumclusterwidenetworkpolicies.cilium.io                  2024-12-15T14:31:26Z
ciliumendpoints.cilium.io                                   2024-12-15T14:31:24Z
ciliumexternalworkloads.cilium.io                           2024-12-15T14:31:23Z
ciliumidentities.cilium.io                                  2024-12-15T14:31:23Z
ciliuml2announcementpolicies.cilium.io                      2024-12-15T14:31:24Z
ciliumloadbalancerippools.cilium.io                         2024-12-15T14:31:23Z
ciliumnetworkpolicies.cilium.io                             2024-12-15T14:31:26Z
ciliumnodeconfigs.cilium.io                                 2024-12-15T14:31:22Z
ciliumnodes.cilium.io                                       2024-12-15T14:31:24Z
ciliumpodippools.cilium.io                                  2024-12-15T14:31:23Z


```

* Kubernetes `NetworkPolicy` 리소스 대신 `CiliumNetworkPolicy` 사용자 지정 리소스를 사용 가능



## 3) hubble ui



```sh

$ cilium hubble enable --ui

```







## 4) 도메인 기반 필터링 설정

Azure 네이티브 네트워크 정책은 IP 또는 네트워크 수준의 제어를 제공하지만, Cilium은 FQDN 기반 제어를 지원하여 도메인 단위의 세부적인 제어가 가능하다.



### (1) CiliumNetworkPolicy

Cilium의 Egress 통신에서 도메인 기반 필터링을 설정하려면 ToFQDNs을 사용합니다.



```sh
cat <<EOF | kubectl -n demo apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-egress-to-specific-domain
spec:
  egress:
    - toFQDNs:
        - matchName: example.com
        - matchName: api.example.com
        - matchName: google.com
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP
  endpointSelector:
    matchLabels:
      app: client
EOF

$ kubectl get CiliumNetworkPolicy -A
NAMESPACE   NAME                              AGE
demo        allow-egress-to-specific-domain   17s


```

**설명:**

* toFQDNs:

​	•	matchName으로 지정된 FQDN(예: example.com)으로의 통신만 허용합니다.

* toPorts:

​	•	TCP 443 포트(HTTPS)에 대한 요청만 허용합니다.

* endpointSelector:

​	•	app: my-app 레이블이 있는 Pod에 정책 적용.



### (2) 예제POD



`client` Pod를 만듭니다. 다음 명령은 `client` Pod에서 Bash를 실행합니다.

```sh
$ kubectl run -it curl -n demo \
    --image=alpine/curl \
    --labels="app=client" \ 
    --command -- sleep 365d

```





```sh
kubectl exec -it <pod-name> -- curl -I https://example.com
kubectl exec -it <pod-name> -- curl -I https://blocked.com

```



허용된 도메인은 정상적으로 응답을 받고, 차단된 도메인은 연결이 실패한다.





### (3) Cilium 및 FQDN 기반 필터링의 제한사항



* **DNS 의존성**:

​	•	ToFQDNs은 DNS 쿼리에 의존하므로, 도메인이 IP로 변환되지 않으면 통신이 차단될 수 있다.

* **DNS 캐싱**:

​	•	도메인의 IP 주소가 변경되면 DNS TTL 이후에 정책이 적용된다.

* **성능**:

​	•	도메인 기반 필터링은 DNS 요청을 모니터링하므로 약간의 성능 오버헤드가 있을 수 있다.







# 5. Cilium on k8s

Azure CNI powered by Cilium은 기본적으로 L3/L4 계층(IP, 포트)에서만 트래픽을 처리하도록 설계되어 있으며, L7 계층의 정책을 처리할 기능이 없다. 따라서 **ToFQDNs**(도메인 기반 정책)과 같은 Cilium의 고급 기능을 사용할 수 없다.

그러므로, K8s 에서 **Cilium**을 설치하여 Egress 통신을 도메인 단위로 통제하는 방법을 알아본자. 

**Cilium**은 eBPF 기반 네트워크 플러그인으로, 도메인 기반 정책(Egress Domain Policy)을 설정할 수 있는 고급 네트워크 기능을 제공한다.





## 1) Cilium 설정

### (1) Cilium 설치

Cilium CLI는 클러스터에 Cilium을 설치 및 관리하는 데 사용되다.

```sh
curl -L --remote-name https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64
chmod +x cilium-linux-amd64
sudo mv cilium-linux-amd64 /usr/local/bin/cilium


$ cilium version
cilium-cli: v0.15.0 compiled with go1.20.4 on linux/amd64
cilium image (default): v1.13.4
cilium image (stable): v1.16.4
cilium image (running): 1.16.4


```

Cilium을 Helm을 사용하여 K8S 클러스터에 설치합니다.

```sh
helm repo add cilium https://helm.cilium.io/
helm repo update


$ helm search repo cilium
NAME            CHART VERSION   APP VERSION     DESCRIPTION
cilium/cilium   1.16.4          1.16.4          eBPF-based Networking, Security, and Observability
cilium/tetragon 1.3.0           1.3.0           Helm chart for Tetragon


$ kubectl create ns kube-system

$ helm -n kube-system upgrade --install cilium cilium/cilium --version 1.16.4

###############
  --set hubble.relay.enabled=true \
  --set hubble.ui.enabled=true \
  --set egressGateway.enabled=true
  
  --set azure.enabled=true \
###############

NAME: cilium
LAST DEPLOYED: Sun Dec 15 15:56:35 2024
NAMESPACE: cilium-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
You have successfully installed Cilium with Hubble Relay and Hubble UI.

Your release version is 1.16.4.

For any further help, visit https://docs.cilium.io/en/v1.16/gettinghelp


# 확인
$ helm -n kube-system ls


# 삭제시...
$ helm -n kube-system delete cilium

```





#### helm history

```sh
# history
$ helm -n kube-system history cilium
REVISION        UPDATED                         STATUS          CHART           APP VERSION     DESCRIPTION
1               Tue Dec 17 05:09:23 2024        superseded      cilium-1.16.4   1.16.4          Install complete
2               Tue Dec 17 05:22:24 2024        deployed        cilium-1.16.4   1.16.4          Upgrade complete



# 현재 values 확인
$ helm -n kube-system get values cilium

# 이전 값 확인
$ helm -n kube-system get values cilium --revision 1


```





#### Ingress 

```sh
# ingress
$ cat <<EOF | kubectl -n kube-system apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hubble-ui-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: "hubble-ui.4.230.41.115.nip.io"
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: hubble-ui
            port:
              number: 80
EOF

```







## 2) 도메인 기반 필터링 설정

참고링크 : https://docs.cilium.io/en/stable/security/dns/



Azure 네이티브 네트워크 정책은 IP 또는 네트워크 수준의 제어를 제공하지만, Cilium은 FQDN 기반 제어를 지원하여 도메인 단위의 세부적인 제어가 가능하다.





### (1) CiliumNetworkPolicy

Cilium에서는 **NetworkPolicy**(Kubernetes 기본)나 **CiliumNetworkPolicy**(CNP)가 적용되면 **기본 동작**이 **Default-Deny**로 설정된다. 이는 보안 강화를 위한 기본 설계이다.

즉, **CiliumNetworkPolicy**가 한 개라도 생성되면 해당 네임스페이스의 Pod들에 대해 **모든 트래픽이 기본적으로 차단**되며, 명시적으로 허용된 규칙만 동작하게 된다.

Cilium은 보안을 최우선으로 하기 때문에 정책이 하나라도 설정되면 기본적으로 **“Zero Trust”** 모델을 따른다.





#### DNS 트래픽 허용 정책 추가

toFQDNs가 작동하기 위해서는 DNS 트래픽을 명시적으로 허용해야 한다.

Cilium의 Egress 통신에서 도메인 기반 필터링을 설정하려면 ToFQDNs을 사용한다.

```sh

$ kubectl create ns demo


$ cat <<EOF | kubectl -n demo apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-dns
spec:
  endpointSelector: {} # 모든 POD에 적용
  egress:
    - toEndpoints:
        - matchLabels:
            k8s:io.kubernetes.pod.namespace: kube-system
            k8s:k8s-app: kube-dns
      toPorts:
        - ports:
            - port: "53"
              protocol: ANY
          rules:
            dns:
            - matchPattern: "*"
EOF


## 참고 -------------------

  egress:
    - toEndpoints:
        - matchLabels:
            k8s:io.kubernetes.pod.namespace: kube-system
            k8s:k8s-app: kube-dns
## 참고 -------------------
            
```



#### **정확한 FQDN 명시**



```sh
$ cat <<EOF | kubectl -n demo apply -f -
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-egress-to-specific-domain
spec:
  egress:
    - toFQDNs:
        - matchName: example.com
        - matchName: google.com
        - matchPattern: "*.google.com"
        - matchPattern: "*.github.com"
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP
  endpointSelector:
    matchLabels:
      app: client
EOF


$ kubectl -n demo get CiliumNetworkPolicy -A
NAMESPACE   NAME                              AGE
demo        allow-egress-to-specific-domain   17s



$ kubectl -n demo delete CiliumNetworkPolicy demo



```

**설명:**

* toFQDNs:

​	•	matchName으로 지정된 FQDN(예: example.com)으로의 통신만 허용합니다.

* toPorts:

​	•	TCP 443 포트(HTTPS)에 대한 요청만 허용합니다.

* endpointSelector:

​	•	app: my-app 레이블이 있는 Pod에 정책 적용.





#### 참고 : NetworkPolicy

```sh

$ cat <<EOF | kubectl -n demo apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-specific-pod
spec:
  podSelector:
    matchLabels:
      app: client
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: backend
    ports:
    - protocol: TCP
      port: 443
EOF
      
```









### (2) 예제POD



`client` Pod를 만듭니다. 다음 명령은 `client` Pod에서 Bash를 실행합니다.

```sh
$ kubectl run curl -n demo \
    --image=alpine/curl \
    --labels="app=client" \ 
    --command -- sleep 365d


```





```sh

$ kubectl -n demo exec -it curl -- sh


# 성공
$ curl https://google.com -i -k -m 3
HTTP/2 301
location: https://www.google.com/

# 성공
$ curl -i -k https://github.com


# naver.com 은 막혀 있어서 나가지 않음
$ curl https://naver.com


```



허용된 도메인은 정상적으로 응답을 받고, 차단된 도메인은 연결이 실패한다.





### (3) Cilium 및 FQDN 기반 필터링의 제한사항



* **DNS 의존성**:

​	•	ToFQDNs은 DNS 쿼리에 의존하므로, 도메인이 IP로 변환되지 않으면 통신이 차단될 수 있다.

* **DNS 캐싱**:

​	•	도메인의 IP 주소가 변경되면 DNS TTL 이후에 정책이 적용된다.

* **성능**:

​	•	도메인 기반 필터링은 DNS 요청을 모니터링하므로 약간의 성능 오버헤드가 있을 수 있다.





### (4) 기본 Default-Deny를 허용으로 변경하는 방법



기본적으로 모든 egress를 **허용**하고 싶은 경우, 아래와 같은 **“허용-모든-트래픽”** 정책을 정의해야 한다.



```sh

apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-all-egress
  namespace: demo
spec:
  description: "Allow all egress traffic"
  endpointSelector: {} # 모든 Pod에 적용
  egress:
    - {}
    
```





## 3) Trouble Shooting



### (1) curl 실패 현상

#### 현상

```
curl 문장 입력시 timeout 발생

```



#### hubble 로 관찰

```sh
# cilium pod 내로 진입
$ kubeclt -n kube-system exec -it cilium-jxgk6 - sh


# hubble observe 명령으로 관찰
$ hubble observe --namespace demo --follow


Dec 17 07:07:30.342: demo/curl:44310 (ID:15173) <> 142.250.207.110:443 (world) policy-verdict:none EGRESS DENIED (TCP Flags: SYN)
Dec 17 07:07:30.342: demo/curl:44310 (ID:15173) <> 142.250.207.110:443 (world) Policy denied DROPPED (TCP Flags: SYN)
Dec 17 07:07:31.344: demo/curl:44310 (ID:15173) <> 142.250.207.110:443 (world) policy-verdict:none EGRESS DENIED (TCP Flags: SYN)
Dec 17 07:07:31.344: demo/curl:44310 (ID:15173) <> 142.250.207.110:443 (world) Policy denied DROPPED (TCP Flags: SYN)
Dec 17 07:07:32.368: demo/curl:44310 (ID:15173) <> 142.250.207.110:443 (world) policy-verdict:none EGRESS DENIED (TCP Flags: SYN)
Dec 17 07:07:32.368: demo/curl:44310 (ID:15173) <> 142.250.207.110:443 (world) Policy denied DROPPED (TCP Flags: SYN)


```







# 6. Cilium EgressGateway



https://tech.kakaopay.com/post/cilium-egress-gateway/